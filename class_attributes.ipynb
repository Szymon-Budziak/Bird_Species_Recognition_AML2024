{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cruse\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cruse\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B4_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B4_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import random\n",
    "import os\n",
    "\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, attributes_tensor, transform=None, is_train=True):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.attributes_tensor = attributes_tensor\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            img_name = str(self.dataframe.iloc[idx, 0]).lstrip('/')\n",
    "            img_path = os.path.join(self.img_dir, img_name)\n",
    "            label = self.dataframe.iloc[idx, 1] - 1  # Convert to 0-indexed\n",
    "            attributes = self.attributes_tensor[label]\n",
    "        else:\n",
    "            img_name = str(self.dataframe.iloc[idx, 1]).lstrip('/')\n",
    "            img_path = os.path.join(self.img_dir, img_name)\n",
    "            label = str(self.dataframe.iloc[idx, 0])\n",
    "            attributes = torch.zeros(self.attributes_tensor.size(1))\n",
    "            \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label, attributes\n",
    "\n",
    "class BirdClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=200, attribute_dim=312):\n",
    "        super(BirdClassifier, self).__init__()\n",
    "        # Use EfficientNet-B4 as backbone\n",
    "        self.backbone = models.efficientnet_b4(pretrained=True)\n",
    "        backbone_out = 1792  # EfficientNet-B4 output features\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for param in list(self.backbone.parameters())[:-30]:  # Keep last few layers trainable\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        # Attribute processing path\n",
    "        self.attribute_processor = nn.Sequential(\n",
    "            nn.Linear(attribute_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Combine features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(backbone_out + 256, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, attributes):\n",
    "        # Process image\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # Process attributes\n",
    "        attr_features = self.attribute_processor(attributes)\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat((x, attr_features), dim=1)\n",
    "        output = self.classifier(combined)\n",
    "        \n",
    "        return output\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (images, labels, attributes) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            attributes = attributes.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, attributes)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "                      f'Batch {i+1}/{len(train_loader)}, '\n",
    "                      f'Loss: {loss.item():.4f}, ')\n",
    "            \n",
    "        train_acc = 100. * correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels, attributes in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                attributes = attributes.to(device)\n",
    "                \n",
    "                outputs = model(images, attributes)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Train Loss: {running_loss/len(train_loader):.4f}')\n",
    "        print(f'Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Acc: {val_acc:.2f}%')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            \n",
    "    return model\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(380),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(400),\n",
    "    transforms.CenterCrop(380),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load data and create datasets\n",
    "attributes = np.load(\"data/attributes.npy\")\n",
    "attributes_tensor = torch.tensor(attributes, dtype=torch.float32)\n",
    "\n",
    "train_data = pd.read_csv(\"data/train_images.csv\")\n",
    "test_data = pd.read_csv(\"data/test_images_path.csv\")\n",
    "\n",
    "# Split train data into train and validation\n",
    "train_size = int(0.9 * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
    "\n",
    "train_dataset = BirdDataset(train_dataset, \"data/train_images\", attributes_tensor, transform=train_transform)\n",
    "val_dataset = BirdDataset(val_dataset, \"data/train_images\", attributes_tensor, transform=val_transform)\n",
    "test_dataset = BirdDataset(test_data, \"data/test_images\", attributes_tensor, transform=val_transform, is_train=False)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Initialize model and training components\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = BirdClassifier().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=20, device=device)\n",
    "\n",
    "# Generate predictions\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, ids, attributes in test_loader:\n",
    "        images = images.to(device)\n",
    "        attributes = attributes.to(device)\n",
    "        \n",
    "        outputs = model(images, attributes)\n",
    "        _, predicted = outputs.max(1)\n",
    "        predictions.extend(zip(ids, predicted.cpu().numpy() + 1))\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame(predictions, columns=['id', 'label'])\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
