{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1VxkTgcTDDL",
        "outputId": "6f2412ed-6834-4b5c-cb95-b7099823cb56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n",
            "aml-2024-feather-in-focus.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 4.6342\n",
            "Epoch [2/10], Loss: 2.9616\n",
            "Epoch [3/10], Loss: 1.7987\n",
            "Epoch [4/10], Loss: 1.0853\n",
            "Epoch [5/10], Loss: 0.6458\n",
            "Epoch [6/10], Loss: 0.3609\n",
            "Epoch [7/10], Loss: 0.1788\n",
            "Epoch [8/10], Loss: 0.0944\n",
            "Epoch [9/10], Loss: 0.0436\n",
            "Epoch [10/10], Loss: 0.0228\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from torch import nn, optim\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c aml-2024-feather-in-focus\n",
        "with zipfile.ZipFile(\"aml-2024-feather-in-focus.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"data\")\n",
        "os.listdir(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load attributes and class names\n",
        "attributes = np.load(\"data/attributes.npy\")\n",
        "class_names = np.load(\"data/class_names.npy\", allow_pickle=True).item()\n",
        "\n",
        "# Load training and test data\n",
        "train_data = pd.read_csv(\"data/train_images.csv\")\n",
        "test_data = pd.read_csv(\"data/test_images_path.csv\")\n",
        "\n",
        "# Transformations for image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Prepare attributes as tensors\n",
        "attributes_tensor = torch.tensor(attributes, dtype=torch.float32).to('cuda')"
      ],
      "metadata": {
        "id": "ZuQoSxPaBmcj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset Class\n",
        "class BirdDataset(Dataset):\n",
        "    def __init__(self, dataframe, img_dir, attributes_tensor, transform=None, is_train=True):\n",
        "        self.dataframe = dataframe\n",
        "        self.img_dir = img_dir\n",
        "        self.attributes_tensor = attributes_tensor\n",
        "        self.transform = transform\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      if self.is_train:\n",
        "          # For training data: image_path is in column 0, label in column 1\n",
        "          img_name = str(self.dataframe.iloc[idx, 0]).lstrip('/')\n",
        "          img_path = os.path.join(self.img_dir, img_name)\n",
        "          label = self.dataframe.iloc[idx, 1] - 1  # Convert labels to 0-indexed\n",
        "          attributes = self.attributes_tensor[label]\n",
        "      else:\n",
        "          # For testing data: id in column 0, image_path in column 1\n",
        "          img_name = str(self.dataframe.iloc[idx, 1]).lstrip('/')\n",
        "          img_path = os.path.join(self.img_dir, img_name)\n",
        "          label = str(self.dataframe.iloc[idx, 0])  # Use ID as label for test data\n",
        "          attributes = torch.zeros(self.attributes_tensor.size(1))  # Dummy attributes for test data\n",
        "\n",
        "      image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "      if self.transform:\n",
        "          image = self.transform(image)\n",
        "\n",
        "      return image, label, attributes"
      ],
      "metadata": {
        "id": "MIPpU-YIBniN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "class BirdClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=200, attribute_dim=312):\n",
        "        super(BirdClassifier, self).__init__()\n",
        "        self.cnn = models.resnet50(pretrained=True)\n",
        "        self.cnn.fc = nn.Identity()  # Remove last layer\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(2048 + attribute_dim, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x, attributes):\n",
        "        cnn_features = self.cnn(x)\n",
        "        combined = torch.cat((cnn_features, attributes), dim=1)\n",
        "        x = torch.relu(self.fc1(combined))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "model = BirdClassifier().to('cuda')\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Data Loaders\n",
        "train_dataset = BirdDataset(train_data, \"data/train_images\", attributes_tensor, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = BirdDataset(test_data, \"/content/data/test_images\", attributes_tensor, transform=transform, is_train=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "SFCYsk6eBoDM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels, attributes in train_loader:\n",
        "        images, labels, attributes = images.to('cuda'), labels.to('cuda'), attributes.to('cuda')\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images, attributes)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZhVLJAzBm9a",
        "outputId": "588d5e2d-9e6e-4683-af47-14a7bb27a06b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 4.6481\n",
            "Epoch [2/10], Loss: 2.9418\n",
            "Epoch [3/10], Loss: 1.7772\n",
            "Epoch [4/10], Loss: 1.0880\n",
            "Epoch [5/10], Loss: 0.6433\n",
            "Epoch [6/10], Loss: 0.3537\n",
            "Epoch [7/10], Loss: 0.1659\n",
            "Epoch [8/10], Loss: 0.0780\n",
            "Epoch [9/10], Loss: 0.0376\n",
            "Epoch [10/10], Loss: 0.0223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "submission = []\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        images, ids, attributes = batch  # Unpack the batch\n",
        "        images = images.to(device)\n",
        "\n",
        "        # First, get the model's predictions without attributes\n",
        "        initial_outputs = model(images, torch.zeros(images.size(0), 312).to(device))\n",
        "        _, predicted_labels = torch.max(initial_outputs, 1)\n",
        "\n",
        "        # Then, use these predicted labels to get the corresponding attributes\n",
        "        attributes = attributes_tensor[predicted_labels]\n",
        "\n",
        "        # Now, make the final prediction using these attributes\n",
        "        outputs = model(images, attributes)\n",
        "        _, final_predictions = torch.max(outputs, 1)\n",
        "\n",
        "        # Convert ids and predictions to numpy arrays\n",
        "        ids_np = ids.cpu().numpy() if isinstance(ids, torch.Tensor) else np.array(ids)\n",
        "        preds_np = final_predictions.cpu().numpy()\n",
        "\n",
        "        submission.extend(zip(ids_np, preds_np + 1))  # Add 1 to predictions if classes are 1-indexed\n",
        "# Create submission DataFrame\n",
        "submission_df = pd.DataFrame(submission, columns=['id', 'label'])\n",
        "\n",
        "# Save submission file\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gys8JH4oeo4O",
        "outputId": "c8351c18-a95c-4f21-890e-c91fa7de6da0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created successfully!\n"
          ]
        }
      ]
    }
  ]
}